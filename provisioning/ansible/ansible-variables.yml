---

# Common variables.

# login
user: spark

# user password created with:
# python -c 'import crypt; print crypt.crypt("Stream4Flow", "$1$wolF4maertS$")'
user_passwd: $1$wolF4mae$jSX8IG9goPtqVfomlbla6.


# Ipfixcol variables - main



# Set the configuration file path for ipfixcol to load here:
script_path: /usr/local/etc/ipfixcol/
script_filename: startup.xml.udp

#  Kafka variables

kafka_dir: /opt/kafka
kafka_download_url: http://apache.miloslavbrada.cz/kafka/0.10.0.0/kafka_2.11-0.10.0.0.tgz
kafka_filename: kafka_2.11-0.10.0.0
retention: 30000
kafka_maximum_heap_space: "{{(ansible_memtotal_mb * 0.5)|int}}"
kafka_minimum_heap_space: "{{(ansible_memtotal_mb * 0.25)|int}}"


# Spark variables

# download mirrors
url_spark: "http://apache.miloslavbrada.cz/spark/spark-1.6.2/spark-1.6.2-bin-hadoop2.6.tgz"
url_kafka_assembly: "http://search.maven.org/remotecontent?filepath=org/apache/spark/spark-streaming-kafka-assembly_2.10/1.6.2/spark-streaming-kafka-assembly_2.10-1.6.2.jar"

# Name of spark directory after inflating downloaded archive
spark_inflated_dir_name: spark-1.6.2-bin-hadoop2.6

# spark test settings
spark_batch_size: 5000
spark_worker_cores: 2
# spark worker memory in MB
spark_worker_memory: "{{ ansible_memtotal_mb }}"
spark_masterurl: spark://{{ masterIP }}:7077

# Web variables

# CSR subject
cert_subj: "/C=CZ/ST=CzechRepublic/L=Brno/O=Stream4Flow/OU=Stream4Flow/CN={{ ansible_host }}"

web2py_passwd: password

